{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentences(json_file_path, max_length=512):\n",
    "    processed_sentences = []\n",
    "    \n",
    "    # read json file\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        sentences_data = json.load(file)\n",
    "    \n",
    "    # iterate each sentence\n",
    "    for entry in sentences_data:\n",
    "        sentence = entry['sentence']\n",
    "        \n",
    "        # tokenize and truncate\n",
    "        tokens = tokenizer(sentence, truncation=True, max_length=512, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "        # convert to text\n",
    "        truncated_sentence = tokenizer.decode(tokens['input_ids'][0], skip_special_tokens=True)\n",
    "        \n",
    "        # save processed sentence\n",
    "        processed_sentences.append(truncated_sentence)\n",
    "    \n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    top_k=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./speech_json/37_nixon_speech.json', 'r') as file:\n",
    "#     nixon_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/38_ford_speech.json', 'r') as file:\n",
    "#     ford_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/39_carter_speech.json', 'r') as file:\n",
    "#     carter_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/40_reagan_speech.json', 'r') as file:\n",
    "#     reagan_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/41_herbertbush_speech.json', 'r') as file:\n",
    "#     herbertbush_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/42_clinton_speech.json', 'r') as file:\n",
    "#     clinton_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/43_walkerbush_speech.json', 'r') as file:\n",
    "#     walkerbush_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/44_obama_speech.json', 'r') as file:\n",
    "#     obama_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/45_trump_speech.json', 'r') as file:\n",
    "#     trump_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/46_biden_speech.json', 'r') as file:\n",
    "#     biden_speech = json.load(file)\n",
    "\n",
    "# with open('./speech_json/47_vicepresident_biden_speech.json', 'r') as file:\n",
    "#     vicepresident_biden_speech = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./speech_json/deduplicated_canada.json', 'r') as file:\n",
    "    canada_speech = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(speech_file, output_file):\n",
    "    results = []\n",
    "\n",
    "    for entry in speech_file:\n",
    "        sentence = entry['sentence']\n",
    "        date = entry['date']\n",
    "        tokens = tokenizer(sentence, truncation=True, max_length=512, return_tensors=\"pt\", padding=True)\n",
    "        truncated_sentence = tokenizer.decode(tokens['input_ids'][0], skip_special_tokens=True)\n",
    "        result = classify(truncated_sentence)\n",
    "        sentiment_score = result[0][0]['label'].split(' ')[0]\n",
    "\n",
    "        # Collect sentences with their scores and dates\n",
    "        results.append({\n",
    "            \"date\": date,\n",
    "            \"sentiment_score\": sentiment_score,\n",
    "            \"sentence\": sentence\n",
    "        })\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nixon_results = calculate_scores(nixon_speech, 'nixon_sentiment_scores.json')\n",
    "# ford_results = calculate_scores(ford_speech, 'ford_sentiment_scores.json')\n",
    "# carter_results = calculate_scores(carter_speech, 'carter_sentiment_scores.json')\n",
    "# reagan_results = calculate_scores(reagan_speech, 'reagan_sentiment_scores.json')\n",
    "# herbertbush_results = calculate_scores(herbertbush_speech, 'herbertbush_sentiment_scores.json')\n",
    "# clinton_results = calculate_scores(clinton_speech, 'clinton_sentiment_scores.json')\n",
    "# walkerbush_results = calculate_scores(walkerbush_speech, 'walkerbush_sentiment_scores.json')\n",
    "# obama_results = calculate_scores(obama_speech, 'obama_sentiment_scores.json')\n",
    "# trump_results = calculate_scores(trump_speech, 'trump_sentiment_scores.json')\n",
    "# biden_results = calculate_scores(biden_speech, 'biden_sentiment_scores.json')\n",
    "# vicepresident_biden_results = calculate_scores(vicepresident_biden_speech, 'vicepresident_biden_sentiment_scores.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_sentiment_scores = calculate_scores(canada_speech, 'canada_sentiment_scores.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./sentiment_scores_json/nixon_sentiment_scores.json', 'r') as file:\n",
    "#     nixon_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/ford_sentiment_scores.json', 'r') as file:\n",
    "#     ford_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/carter_sentiment_scores.json', 'r') as file:\n",
    "#     carter_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/reagan_sentiment_scores.json', 'r') as file:\n",
    "#     reagan_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/herbertbush_sentiment_scores.json', 'r') as file:\n",
    "#     herbertbush_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/clinton_sentiment_scores.json', 'r') as file:\n",
    "#     clinton_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/walkerbush_sentiment_scores.json', 'r') as file:\n",
    "#     walkerbush_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/obama_sentiment_scores.json', 'r') as file:\n",
    "#     obama_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/trump_sentiment_scores.json', 'r') as file:\n",
    "#     trump_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/biden_sentiment_scores.json', 'r') as file:\n",
    "#     biden_sentiment_scores = json.load(file)\n",
    "\n",
    "# with open('./sentiment_scores_json/vicepresident_biden_sentiment_scores.json', 'r') as file:\n",
    "#     vicepresident_biden_sentiment_scores = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_statistics(scores, presidentname):\n",
    "\n",
    "    sentiment_scores = [int(score['sentiment_score']) for score in scores]\n",
    "\n",
    "    if not sentiment_scores:\n",
    "        return None, None, None\n",
    "    \n",
    "    average_sentiment_score = np.mean(sentiment_scores)\n",
    "    median_sentiment_score = np.median(sentiment_scores)\n",
    "    std_dev_sentiment_score = np.std(sentiment_scores)\n",
    "\n",
    "    print(f\"president_name: {presidentname}\")\n",
    "    print(f\"average_sentiment_score: {average_sentiment_score:.3f}\")\n",
    "    print(f\"median_sentiment_score: {median_sentiment_score:.3f}\")\n",
    "    print(f\"std_dev_sentiment_score: {std_dev_sentiment_score:.3f}\")\n",
    "\n",
    "    results = {\n",
    "        \"president_name\": presidentname,\n",
    "        \"average_sentiment_score\": average_sentiment_score,\n",
    "        \"median_sentiment_score\": median_sentiment_score,\n",
    "        \"std_dev_sentiment_score\": std_dev_sentiment_score,\n",
    "\n",
    "    }\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    with open('sentiment_statistics.json', 'a') as outfile:\n",
    "        json.dump(results, outfile, indent=4)\n",
    "    \n",
    "    return average_sentiment_score, median_sentiment_score, std_dev_sentiment_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nixon_sentiment_statistics = sentiment_statistics(nixon_sentiment_scores, \"nixon\")\n",
    "# ford_sentiment_statistics = sentiment_statistics(ford_sentiment_scores, \"ford\")\n",
    "# carter_sentiment_statistics = sentiment_statistics(carter_sentiment_scores, \"carter\")\n",
    "# reagan_sentiment_statistics = sentiment_statistics(reagan_sentiment_scores, \"reagan\")\n",
    "# herbertbush_sentiment_statistics = sentiment_statistics(herbertbush_sentiment_scores, \"herbertbush\")\n",
    "# clinton_sentiment_statistics = sentiment_statistics(clinton_sentiment_scores, \"clinton\")\n",
    "# walkerbush_sentiment_statistics = sentiment_statistics(walkerbush_sentiment_scores, \"walkerbush\")\n",
    "# obama_sentiment_statistics = sentiment_statistics(obama_sentiment_scores, \"obama\")\n",
    "# trump_sentiment_statistics = sentiment_statistics(trump_sentiment_scores, \"trump\")\n",
    "#biden_sentiment_statistics = sentiment_statistics(biden_sentiment_scores, \"biden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_sentiment_scores(sentiment_statistics):\n",
    "    presidents = [entry['president_name'] for entry in sentiment_statistics]\n",
    "    average_sentiment_scores = [entry['average_sentiment_score'] for entry in sentiment_statistics]\n",
    "    median_sentiment_scores = [entry['median_sentiment_score'] for entry in sentiment_statistics]\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Plot average and median sentiment scores\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(presidents, average_sentiment_scores, marker='o', label='Average Sentiment Score')\n",
    "    plt.plot(presidents, median_sentiment_scores, marker='o', label='Median Sentiment Score')\n",
    "    plt.xlabel('President')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Sentiment Scores')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./sentiment_statistics.json', 'r') as file:\n",
    "    sentiment_statistics = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sentiment_scores(sentiment_statistics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
